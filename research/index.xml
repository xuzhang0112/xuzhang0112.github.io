<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Research on Xu Zhang&#39;s Blog</title>
    <link>https://xuzhang0112.github.io/research/</link>
    <description>Recent content in Research on Xu Zhang&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>© 2025 Xu Zhang</copyright>
    <lastBuildDate>Thu, 10 Apr 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://xuzhang0112.github.io/research/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Medical NLP</title>
      <link>https://xuzhang0112.github.io/research/med_nlp/</link>
      <pubDate>Thu, 10 Apr 2025 00:00:00 +0000</pubDate>
      
      <guid>https://xuzhang0112.github.io/research/med_nlp/</guid>
      <description>&lt;h2 class=&#34;relative group&#34;&gt;ICD coding 
    &lt;div id=&#34;icd-coding&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#icd-coding&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;ICD-9: &lt;a href=&#34;https://archive.cdc.gov/#/details?url=https://www.cdc.gov/nchs/icd/icd9cm.htm&#34; target=&#34;_blank&#34;&gt;ICD-9官方网站&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/jamesmullenbach/caml-mimic&#34; target=&#34;_blank&#34;&gt;MIMIC-III official splits&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://paperswithcode.com/sota/medical-code-prediction-on-mimic-iii&#34; target=&#34;_blank&#34;&gt;MIMIC-III Leaderboard&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/thomasnguyen92/MIMIC-IV-ICD-data-processing&#34; target=&#34;_blank&#34;&gt;MIMIC-IV official splits&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;UMLS: &lt;a href=&#34;https://www.nlm.nih.gov/research/umls/quickstart.html&#34; target=&#34;_blank&#34;&gt;Quick Start&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Metathesaurus&lt;/strong&gt;: Terms and codes from many vocabularies, including CPT®, ICD-10-CM, LOINC®, MeSH®, RxNorm, and SNOMED CT®&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Semantic Network&lt;/strong&gt;: semantic types &amp;amp; their relationships (semantic relations)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SPECIALIST Lexicon and Lexical Tools&lt;/strong&gt;: NLP tools&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ICD-10: &lt;a href=&#34;https://icd.who.int/icdapi&#34; target=&#34;_blank&#34;&gt;ICD10官方API&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Metrics: &lt;a href=&#34;https://developer.aliyun.com/article/1258690&#34; target=&#34;_blank&#34;&gt;单标签多分类：precision = recall =  micro f1 = accuracy&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Blogs &amp;amp; Papers:&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Medical Image Computing</title>
      <link>https://xuzhang0112.github.io/research/med_img/</link>
      <pubDate>Fri, 28 Jun 2024 00:00:00 +0000</pubDate>
      
      <guid>https://xuzhang0112.github.io/research/med_img/</guid>
      <description>&lt;h2 class=&#34;relative group&#34;&gt;CT Reconstruction 
    &lt;div id=&#34;ct-reconstruction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#ct-reconstruction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;

&lt;h3 class=&#34;relative group&#34;&gt;Analytical CT reconstruction 
    &lt;div id=&#34;analytical-ct-reconstruction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#analytical-ct-reconstruction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Radon Transform&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/xuzhang0112/pic-repo/main/image-20240506002239402.png&#34; alt=&#34;image-20240506002239402&#34; style=&#34;zoom:50%;&#34; /&gt;
&lt;p&gt;数学形式化描述&lt;/p&gt;
&lt;p&gt;$$
p(s,\theta)=\int^\infty_{-\infty}\int^\infty_{-\infty}f(x,y)\delta(xcos\theta+ysin\theta-s)dxdy
$$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$s,\theta$确定时，相当于仅在直线$xcos\theta+ysin\theta-s=$上作积分&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;代码实现&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-Python&#34; data-lang=&#34;Python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; skimage.transform &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; warp
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;theta &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;arange(&lt;span style=&#34;color:#ae81ff&#34;&gt;180&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# pad&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;padded_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;pad(image, pad_width, mode&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;constant&amp;#39;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                      constant_values&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;center &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; padded_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;//&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# 旋转+投影&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;radon_image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros((padded_image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;shape[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;], len(theta)),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                       dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;image&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dtype)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, angle &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;deg2rad(theta)):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    cos_a, sin_a &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;cos(angle), np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sin(angle)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    R &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;array([[cos_a, sin_a, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;center &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (cos_a &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; sin_a &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                  [&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;sin_a, cos_a, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;center &lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt; (cos_a &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; sin_a &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)],
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;                  [&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    rotated &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; warp(padded_image, R, clip&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;False&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    radon_image[:, i] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; rotated&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sum(&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Sinogram&lt;/strong&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title></title>
      <link>https://xuzhang0112.github.io/research/ai4research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://xuzhang0112.github.io/research/ai4research/</guid>
      <description>&lt;p&gt;AI Research&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://surveyx.cn/list&#34; target=&#34;_blank&#34;&gt;SurveyX&lt;/a&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Deep Learning</title>
      <link>https://xuzhang0112.github.io/research/basic_knowledge/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://xuzhang0112.github.io/research/basic_knowledge/</guid>
      <description>&lt;h2 class=&#34;relative group&#34;&gt;Arcitecture 
    &lt;div id=&#34;arcitecture&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#arcitecture&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;所有类型的神经网络都可以看成是线性变换+交互。线性变换是不变的，即对每一个像素/token/节点的特征向量进行相同的Linear+Activation；交互则取决于具体的任务：CNN的交互是相邻的像素点加权平均，RNN的交互是下一个token依赖上一个token，Transformer的交互是token与token之间的注意力加权平均，GNN的交互是一阶邻域内节点的加权平均。大部分模型结构层面的优化也是根据任务场景来设计新的交互方式。&lt;/p&gt;

&lt;h3 class=&#34;relative group&#34;&gt;CNN 
    &lt;div id=&#34;cnn&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#cnn&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Series&lt;/th&gt;
          &lt;th&gt;Model&lt;/th&gt;
          &lt;th&gt;&lt;/th&gt;
          &lt;th&gt;&lt;/th&gt;
          &lt;th&gt;Time Consumption&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;UNet&lt;/td&gt;
          &lt;td&gt;UNet&lt;/td&gt;
          &lt;td&gt;2014&lt;/td&gt;
          &lt;td&gt;跳跃连接，精细分割&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;RCNN&lt;/td&gt;
          &lt;td&gt;RCNN&lt;/td&gt;
          &lt;td&gt;2013&lt;/td&gt;
          &lt;td&gt;用CNN做Dectection，再用CNN做Classification&lt;/td&gt;
          &lt;td&gt;40-50s&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;Fast-RCNN&lt;/td&gt;
          &lt;td&gt;2015&lt;/td&gt;
          &lt;td&gt;使用同一个CNN计算bounding box和Label&lt;/td&gt;
          &lt;td&gt;2s&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;Faster-RCNN&lt;/td&gt;
          &lt;td&gt;2015&lt;/td&gt;
          &lt;td&gt;去除了Selective Search&lt;/td&gt;
          &lt;td&gt;0.2s&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;Mask-RCNN&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;支持Instance Segmentation&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;YOLO&lt;/td&gt;
          &lt;td&gt;Yolo v1&lt;/td&gt;
          &lt;td&gt;2015&lt;/td&gt;
          &lt;td&gt;用回归问题统一了Bounding Box的坐标预测和类别预测&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;Yolo v2&lt;/td&gt;
          &lt;td&gt;2016&lt;/td&gt;
          &lt;td&gt;支持不同输入尺寸&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;Yolo v3&lt;/td&gt;
          &lt;td&gt;2018&lt;/td&gt;
          &lt;td&gt;支持多标签；引入多尺度；&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;Yolo v4, v5, v6&lt;/td&gt;
          &lt;td&gt;2020&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;2021&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;Yolo v6, v7&lt;/td&gt;
          &lt;td&gt;2022&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;Yolo v8&lt;/td&gt;
          &lt;td&gt;2023&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 class=&#34;relative group&#34;&gt;RNN 
    &lt;div id=&#34;rnn&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#rnn&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;p&gt;感觉已经G了，不想写了，随便写点吧&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>KG for LLM</title>
      <link>https://xuzhang0112.github.io/research/kg4llm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://xuzhang0112.github.io/research/kg4llm/</guid>
      <description>&lt;h2 class=&#34;relative group&#34;&gt;Introduction &amp;amp; Background 
    &lt;div id=&#34;introduction--background&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction--background&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;LLM和KG各有利弊：LLM富含通用知识、擅长语言处理、具有泛化性；KG具有结构化的精确知识，可解释性强，知识专业性强，可演化；&lt;/p&gt;

&lt;h3 class=&#34;relative group&#34;&gt;LLM 
    &lt;div id=&#34;llm&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#llm&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;p&gt;





&lt;figure&gt;
    &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; alt=&#34;image-20240704172235679&#34; src=&#34;https://raw.githubusercontent.com/xuzhang0112/pic-repo/main/202407041722595.png&#34; /&gt;

  
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Encoder-only、Decoder-only、Encoder-Decoder的LLM发展路线图&lt;/p&gt;
&lt;p&gt;





&lt;figure&gt;
    &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; alt=&#34;image-20240704172732196&#34; src=&#34;https://raw.githubusercontent.com/xuzhang0112/pic-repo/main/202407041727026.png&#34; /&gt;

  
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Encoder和Decoder之间的异同，以及Self-Attention的内部结构&lt;/p&gt;

&lt;h3 class=&#34;relative group&#34;&gt;KG 
    &lt;div id=&#34;kg&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#kg&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;p&gt;





&lt;figure&gt;
    &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; alt=&#34;image-20240704173050791&#34; src=&#34;https://raw.githubusercontent.com/xuzhang0112/pic-repo/main/202407041730828.png&#34; /&gt;

  
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;各种类型的KG，包括百科全书、常识、领域知识和多模态的知识图谱&lt;/p&gt;

&lt;h3 class=&#34;relative group&#34;&gt;LLM与KG的结合 
    &lt;div id=&#34;llm与kg的结合&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#llm%e4%b8%8ekg%e7%9a%84%e7%bb%93%e5%90%88&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;p&gt;





&lt;figure&gt;
    &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; alt=&#34;image-20240704173249398&#34; src=&#34;https://raw.githubusercontent.com/xuzhang0112/pic-repo/main/202407041732894.png&#34; /&gt;

  
&lt;/figure&gt;
&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Medical Multimodal</title>
      <link>https://xuzhang0112.github.io/research/med_mm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://xuzhang0112.github.io/research/med_mm/</guid>
      <description>&lt;h2 class=&#34;relative group&#34;&gt;Dataset 
    &lt;div id=&#34;dataset&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#dataset&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;

&lt;h3 class=&#34;relative group&#34;&gt;MIMIC-CXR 
    &lt;div id=&#34;mimic-cxr&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#mimic-cxr&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;p&gt;377,110 images, 227,835 reports&lt;/p&gt;

&lt;h3 class=&#34;relative group&#34;&gt;NIH-CXR 
    &lt;div id=&#34;nih-cxr&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#nih-cxr&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;p&gt;112,120 X-ray images from 30,805 unique patients, with labels of 14 diseases&lt;/p&gt;
&lt;p&gt;The labels are expected to be &amp;gt;90% accurate and suitable for weakly-supervised learning&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>
